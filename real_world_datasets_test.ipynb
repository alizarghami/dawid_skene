{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a66ba800",
   "metadata": {},
   "source": [
    "Visit https://github.com/TrentoCrowdAI/crowdsourced-datasets and follow the instructions to download the datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719c32b6",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "* Handle partially labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d2a5190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# dataset_path = \"../crowdsourced-datasets/binary-classification/Blue Birds/transformed_dataset.csv\"\n",
    "# dataset_path = \"../crowdsourced-datasets/multi-class-classification/Weather Sentiment - AMT/transformed_dataset.csv\"\n",
    "dataset_path = \"../crowdsourced-datasets/my-dataset/transformed_dataset.csv\"\n",
    "\n",
    "df = pd.read_csv(dataset_path).dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05e20b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize labels\n",
    "\n",
    "# Combine unique values\n",
    "unique_values = pd.Series(pd.unique(df[['response', 'goldLabel']].dropna().values.ravel())).sort_values()\n",
    "\n",
    "# Map each unique value to a unique integer\n",
    "value_to_int = pd.Series(range(len(unique_values)), index=unique_values)\n",
    "\n",
    "# Map column to integers\n",
    "df['normal_response'] = df['response'].map(value_to_int)\n",
    "df['normal_goldLabel'] = df['goldLabel'].map(value_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c59a8a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6b/b06mlbt913x_d1_xksxw55hr0000gp/T/ipykernel_44390/3466353011.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  data = df.groupby('taskID').apply(lambda x: dict(zip(x['workerID'], [x['normal_response']]))).to_dict()\n"
     ]
    }
   ],
   "source": [
    "worker_list = df['workerID'].unique()\n",
    "task_list = df['taskID'].unique()\n",
    "label_list = df['normal_goldLabel'].unique()\n",
    "\n",
    "data = df.groupby('taskID').apply(lambda x: dict(zip(x['workerID'], [x['normal_response']]))).to_dict()\n",
    "labels_dictionary = df.drop_duplicates(subset='taskID').set_index('taskID')['normal_goldLabel'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec009ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num Tasks: 7736\n",
      "num Observers: 3\n",
      "num Classes: 6\n"
     ]
    }
   ],
   "source": [
    "print (\"num Tasks:\", len(task_list))\n",
    "print (\"num Observers:\", len(worker_list))\n",
    "print (\"num Classes:\", len(label_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a83c816",
   "metadata": {},
   "source": [
    "# Run Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b55a36b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99238190e-01, 7.36524380e-04, 1.74002775e-05, 3.87238289e-57,\n",
       "        7.88576290e-06],\n",
       "       [9.78211450e-01, 3.26703162e-03, 1.80738461e-02, 2.50816810e-39,\n",
       "        4.47671972e-04],\n",
       "       [9.99238190e-01, 7.36524380e-04, 1.74002775e-05, 3.87238289e-57,\n",
       "        7.88576290e-06],\n",
       "       ...,\n",
       "       [8.50905917e-01, 1.48964424e-01, 1.29658667e-04, 6.49420112e-95,\n",
       "        2.42370901e-16],\n",
       "       [5.67728469e-03, 2.04054734e-02, 9.73917242e-01, 1.89676760e-61,\n",
       "        5.43806694e-15],\n",
       "       [5.67728469e-03, 2.04054734e-02, 9.73917242e-01, 1.89676760e-61,\n",
       "        5.43806694e-15]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dawid_skene import run as run_em\n",
    "\n",
    "_, _, _, _, class_marginals, error_rates, patient_classes = run_em(data, verbose=False)\n",
    "patient_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a4fc71",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ff81368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8d1a036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: %13\n"
     ]
    }
   ],
   "source": [
    "true_labels = list(labels_dictionary.values())\n",
    "estimated_labels = np.argmax(patient_classes, axis=1)\n",
    "\n",
    "accuracy = int(100 * accuracy_score(true_labels, estimated_labels))\n",
    "\n",
    "print(\"Accuracy: %{}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0147e7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the confusion matrices\n",
    "\n",
    "confusion_matrices = []\n",
    "for value in df['workerID'].unique():\n",
    "    worker_df = df[df['workerID'] == value]\n",
    "\n",
    "    confusion_matrices.append(confusion_matrix(worker_df['normal_goldLabel'], worker_df['normal_response'], labels=label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08e463ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frobenius_norm(matrix1, matrix2):\n",
    "    # Convert the input matrices to numpy arrays if they are not already\n",
    "    matrix1 = np.array(matrix1)\n",
    "    matrix2 = np.array(matrix2)\n",
    "    \n",
    "    # Calculate the Frobenius norm of the difference\n",
    "    difference = matrix1 - matrix2\n",
    "    norm = np.linalg.norm(difference, 'fro')\n",
    "    \n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "af028cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 1 3 5 4]\n",
      "confusion matrix 0:\n",
      " [[1433    0    0    0    0    0]\n",
      " [ 346    0  101  231   77   39]\n",
      " [   0    0 4795    0    0    0]\n",
      " [   0    0    0  837    0    0]\n",
      " [   0    0    0    0  125    0]\n",
      " [   0    0    0    0    0   26]] \n",
      "\n",
      "confusion matrix 1:\n",
      " [[1433    0    0    0    0    0]\n",
      " [  71    0  574  144    0    5]\n",
      " [   0    0 4795    0    0    0]\n",
      " [   0    0    0  837    0    0]\n",
      " [   0    0    0    0  125    0]\n",
      " [   0    0    0    0    0   26]] \n",
      "\n",
      "confusion matrix 2:\n",
      " [[1034    0  393    6    0    0]\n",
      " [ 121    0  503  121   48    1]\n",
      " [ 170    0 4528   92    5    0]\n",
      " [   6    0   43  786    2    0]\n",
      " [   0    0    2    1  122    0]\n",
      " [   0    0    0    0    0   26]] \n",
      "\n",
      "error_rates:\n",
      " [[[9.50685062e-01 2.71615334e-02 1.93163337e-02 1.08470790e-03\n",
      "   1.75236298e-03]\n",
      "  [1.26686189e-01 8.59666101e-01 1.16632556e-02 1.98444433e-03\n",
      "   9.81399963e-09]\n",
      "  [4.35631456e-02 1.08910488e-02 9.39156457e-01 5.83350540e-03\n",
      "   5.55842977e-04]\n",
      "  [8.54724594e-19 4.80926531e-58 1.14902337e-02 9.88509766e-01\n",
      "   0.00000000e+00]\n",
      "  [5.80503620e-02 5.98613888e-14 6.83983199e-02 0.00000000e+00\n",
      "   8.73551318e-01]]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(label_list)\n",
    "print('confusion matrix 0:\\n',confusion_matrices[0],'\\n')\n",
    "print('confusion matrix 1:\\n',confusion_matrices[1],'\\n')\n",
    "print('confusion matrix 2:\\n',confusion_matrices[2],'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2778ec30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_rates:\n",
      " [[9.50685062e-01 2.71615334e-02 1.93163337e-02 1.08470790e-03\n",
      "  1.75236298e-03]\n",
      " [1.26686189e-01 8.59666101e-01 1.16632556e-02 1.98444433e-03\n",
      "  9.81399963e-09]\n",
      " [4.35631456e-02 1.08910488e-02 9.39156457e-01 5.83350540e-03\n",
      "  5.55842977e-04]\n",
      " [8.54724594e-19 4.80926531e-58 1.14902337e-02 9.88509766e-01\n",
      "  0.00000000e+00]\n",
      " [5.80503620e-02 5.98613888e-14 6.83983199e-02 0.00000000e+00\n",
      "  8.73551318e-01]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('error_rates:\\n',error_rates[0],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7fca9828",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (6,6) (5,5) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m parameter_error_rate \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean([\u001b[43mfrobenius_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcm_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcm_estimate\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m cm_true, cm_estimate \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(confusion_matrices, error_rates)])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Parameter Estimation Error: \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(parameter_error_rate))\n",
      "Cell \u001b[0;32mIn[35], line 7\u001b[0m, in \u001b[0;36mfrobenius_norm\u001b[0;34m(matrix1, matrix2)\u001b[0m\n\u001b[1;32m      4\u001b[0m matrix2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(matrix2)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Calculate the Frobenius norm of the difference\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m difference \u001b[38;5;241m=\u001b[39m \u001b[43mmatrix1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmatrix2\u001b[49m\n\u001b[1;32m      8\u001b[0m norm \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(difference, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m norm\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (6,6) (5,5) "
     ]
    }
   ],
   "source": [
    "parameter_error_rate = np.mean([frobenius_norm(cm_true, cm_estimate) for cm_true, cm_estimate in zip(confusion_matrices, error_rates)])\n",
    "\n",
    "print(\"Average Parameter Estimation Error: {:.2f}\".format(parameter_error_rate))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
