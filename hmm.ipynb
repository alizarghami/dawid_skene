{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hmmlearn version: 0.3.2\n",
      "pybind11 version: 2.13.6\n",
      "Python version: 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 20:54:21) [Clang 16.0.6 ]\n"
     ]
    }
   ],
   "source": [
    "import hmmlearn\n",
    "import pybind11\n",
    "import sys\n",
    "\n",
    "print(\"hmmlearn version:\", hmmlearn.__version__)\n",
    "print(\"pybind11 version:\", pybind11.__version__)\n",
    "print(\"Python version:\", sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hmmlearn import hmm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "model = hmm.GaussianHMM(n_components=3, covariance_type=\"full\")\n",
    "model.startprob_ = np.array([0.6, 0.3, 0.1])\n",
    "model.transmat_ = np.array([[0.7, 0.2, 0.1],\n",
    "                            [0.3, 0.5, 0.2],\n",
    "                            [0.3, 0.3, 0.4]])\n",
    "model.means_ = np.array([[0.0, 0.0], [3.0, -3.0], [5.0, 10.0]])\n",
    "model.covars_ = np.tile(np.identity(2), (3, 1, 1))\n",
    "X, Z = model.sample(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybind11::handle::inc_ref() is being called while the GIL is either not held or invalid. Please see https://pybind11.readthedocs.io/en/stable/advanced/misc.html#common-sources-of-global-interpreter-lock-errors for debugging advice.\n",
      "If you are convinced there is no bug in your code, you can #define PYBIND11_NO_ASSERT_GIL_HELD_INCREF_DECREF to disable this check. In that case you have to ensure this #define is consistently used for all translation units linked into a given pybind11 extension, otherwise there will be ODR violations. The failing pybind11::handle::inc_ref() call was triggered on a numpy.ndarray object.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "pybind11::handle::inc_ref() PyGILState_Check() failure.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m remodel \u001b[38;5;241m=\u001b[39m hmm\u001b[38;5;241m.\u001b[39mGaussianHMM(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, covariance_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mremodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs_env/lib/python3.12/site-packages/hmmlearn/base.py:485\u001b[0m, in \u001b[0;36m_AbstractHMM.fit\u001b[0;34m(self, X, lengths)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmonitor_\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter):\n\u001b[0;32m--> 485\u001b[0m     stats, curr_logprob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_estep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;66;03m# Compute lower bound before updating model parameters\u001b[39;00m\n\u001b[1;32m    488\u001b[0m     lower_bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_lower_bound(curr_logprob)\n",
      "File \u001b[0;32m~/miniconda3/envs/cs_env/lib/python3.12/site-packages/hmmlearn/base.py:764\u001b[0m, in \u001b[0;36m_AbstractHMM._do_estep\u001b[0;34m(self, X, lengths)\u001b[0m\n\u001b[1;32m    762\u001b[0m curr_logprob \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sub_X \u001b[38;5;129;01min\u001b[39;00m _utils\u001b[38;5;241m.\u001b[39msplit_X_lengths(X, lengths):\n\u001b[0;32m--> 764\u001b[0m     lattice, logprob, posteriors, fwdlattice, bwdlattice \u001b[38;5;241m=\u001b[39m \u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;66;03m# Derived HMM classes will implement the following method to\u001b[39;00m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;66;03m# update their probability distributions, so keep\u001b[39;00m\n\u001b[1;32m    767\u001b[0m     \u001b[38;5;66;03m# a single call to this method for simplicity.\u001b[39;00m\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accumulate_sufficient_statistics(\n\u001b[1;32m    769\u001b[0m         stats, sub_X, lattice, posteriors, fwdlattice,\n\u001b[1;32m    770\u001b[0m         bwdlattice)\n",
      "File \u001b[0;32m~/miniconda3/envs/cs_env/lib/python3.12/site-packages/hmmlearn/base.py:884\u001b[0m, in \u001b[0;36mBaseHMM._fit_log\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit_log\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    883\u001b[0m     log_frameprob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_log_likelihood(X)\n\u001b[0;32m--> 884\u001b[0m     log_prob, fwdlattice \u001b[38;5;241m=\u001b[39m \u001b[43m_hmmc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_log\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstartprob_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransmat_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_frameprob\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    886\u001b[0m     bwdlattice \u001b[38;5;241m=\u001b[39m _hmmc\u001b[38;5;241m.\u001b[39mbackward_log(\n\u001b[1;32m    887\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstartprob_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransmat_, log_frameprob)\n\u001b[1;32m    888\u001b[0m     posteriors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_posteriors_log(fwdlattice, bwdlattice)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: pybind11::handle::inc_ref() PyGILState_Check() failure."
     ]
    }
   ],
   "source": [
    "remodel = hmm.GaussianHMM(n_components=3, covariance_type=\"full\", n_iter=100)\n",
    "remodel.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nWorkers = 5    # Number of Channels\n",
    "nSamples = 45   # Number of Data\n",
    "nClasses = 4    # Number of Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Number of possible observations\n",
    "n_observations = 4\n",
    "\n",
    "# Number of hidden states\n",
    "n_states = 4\n",
    "\n",
    "# Generate random observed data (replace with your actual data)\n",
    "observations = np.random.randint(0, n_observations, size=1000)\n",
    "\n",
    "# Create a Categorical Hidden Markov Model\n",
    "model = hmm.CategoricalHMM(n_components=n_states, n_iter=100)\n",
    "\n",
    "# Fit the model to the observations using the Baum-Welch algorithm\n",
    "model.fit(observations.reshape(-1, 1))\n",
    "\n",
    "# Print the learned parameters\n",
    "print(\"Transition probabilities:\")\n",
    "print(model.transition_prob_)\n",
    "print(\"Emission probabilities:\")\n",
    "print(model.emission_prob_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
