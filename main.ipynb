{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5f66aac-441f-49cd-be07-94bed8b63911",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29605d28-dc14-4c0b-8706-bc3067bc3ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nWorkers = 5    # Number of Channels\n",
    "nSamples = 45   # Number of Data\n",
    "nClasses = 4    # Number of Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94b55a4",
   "metadata": {},
   "source": [
    "# Generate Fake Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c097038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_data_generator import RandomConfusionMatrixChannel, DataGenerator\n",
    "\n",
    "def generate_sample_data(nSamples, nWorkers, nClass, truePredictionRate=.8):\n",
    "    workers = []\n",
    "    confusion_matrices = []\n",
    "    for _ in range(nWorkers):\n",
    "        worker = RandomConfusionMatrixChannel()\n",
    "        worker.train(nClass, truePredictionRate)\n",
    "        workers.append(worker)\n",
    "        confusion_matrices.append(worker.confusionMatrix)\n",
    "\n",
    "    samples = {}\n",
    "    lables = []\n",
    "    data_generator = DataGenerator(nClass)\n",
    "    for n in range(nSamples):\n",
    "        data = data_generator.generate()\n",
    "        sample = {w:[workers[w].estimate(data)] for w in range(nWorkers)}\n",
    "        samples[n] = sample\n",
    "        lables.append(data.label)\n",
    "\n",
    "\n",
    "    return (samples, lables, confusion_matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d7d247",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9c7f7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, labels, confusion_matrices = generate_sample_data(nSamples, nWorkers, nClasses, .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ed4df3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dawid_skene import run as run_em\n",
    "\n",
    "_, _, _, _, class_marginals, error_rates, patient_classes = run_em(samples, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00239362",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b282b16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58699cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frobenius_norm(matrix1, matrix2):\n",
    "    # Convert the input matrices to numpy arrays if they are not already\n",
    "    matrix1 = np.array(matrix1)\n",
    "    matrix2 = np.array(matrix2)\n",
    "    \n",
    "    # Calculate the Frobenius norm of the difference\n",
    "    difference = matrix1 - matrix2\n",
    "    norm = np.linalg.norm(difference, 'fro')\n",
    "    \n",
    "    return norm\n",
    "\n",
    "def one_hot_encode(x, n_classes):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "     \"\"\"\n",
    "    return np.eye(n_classes)[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4ca4ad",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "Run this cell only if true labels are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b92ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "true_labels = labels\n",
    "estimated_labels = np.argmax(patient_classes, axis=1)\n",
    "\n",
    "accuracy = int(100 * accuracy_score(true_labels, estimated_labels))\n",
    "\n",
    "print(\"Accuracy: %{}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8de8083",
   "metadata": {},
   "source": [
    "### Average Parameter Estimation Error\n",
    "Run this cell only if true confusion matrices are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d434f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_error_rate = np.mean([frobenius_norm(cm_true, cm_estimate) for cm_true, cm_estimate in zip(confusion_matrices, error_rates)])\n",
    "\n",
    "print(\"Average Parameter Estimation Error: {:.2f}\".format(parameter_error_rate))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
