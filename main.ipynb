{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b282b16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f66aac-441f-49cd-be07-94bed8b63911",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "29605d28-dc14-4c0b-8706-bc3067bc3ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nWorkers = 5    # Number of Channels\n",
    "nSamples = 450   # Number of Data\n",
    "nClasses = 4    # Number of Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94b55a4",
   "metadata": {},
   "source": [
    "# Generate Fake Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c097038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_data_generator import RandomConfusionMatrixChannel, DataGenerator\n",
    "\n",
    "def generate_sample_data(nSamples, nWorkers, nClass, truePredictionRate=.8):\n",
    "    workers = []\n",
    "    confusion_matrices = []\n",
    "    for _ in range(nWorkers):\n",
    "        worker = RandomConfusionMatrixChannel()\n",
    "        worker.train(nClass, truePredictionRate)\n",
    "        workers.append(worker)\n",
    "        confusion_matrices.append(worker.confusionMatrix)\n",
    "\n",
    "    samples = {}\n",
    "    lables = []\n",
    "    data_generator = DataGenerator(nClass)\n",
    "    for n in range(nSamples):\n",
    "        data = data_generator.generate()\n",
    "        sample = {w:[workers[w].estimate(data)] for w in range(nWorkers)}\n",
    "        samples[n] = sample\n",
    "        lables.append(data.label)\n",
    "\n",
    "\n",
    "    return (samples, lables, confusion_matrices)\n",
    "\n",
    "\n",
    "def generate_temporal_dependent_data(nSamples, nWorkers, nClass, nActivityChunk, truePredictionRate=.8):\n",
    "    workers = []\n",
    "    confusion_matrices = []\n",
    "    for _ in range(nWorkers):\n",
    "        worker = RandomConfusionMatrixChannel()\n",
    "        worker.train(nClass, truePredictionRate)\n",
    "        workers.append(worker)\n",
    "        confusion_matrices.append(worker.confusionMatrix)\n",
    "\n",
    "    samples = {}\n",
    "    lables = []\n",
    "    data_generator = DataGenerator(nClass)\n",
    "    \n",
    "    chunkSize = nSamples // nActivityChunk\n",
    "\n",
    "    for n in range(nActivityChunk):\n",
    "        data = data_generator.generate()\n",
    "        for m in range(chunkSize):\n",
    "            index = (n*chunkSize) + m\n",
    "            sample = {w:[workers[w].estimate(data)] for w in range(nWorkers)}\n",
    "            samples[index] = sample\n",
    "            lables.append(data.label)\n",
    "\n",
    "    data = data_generator.generate()\n",
    "    for n in range(len(lables), nSamples):\n",
    "        sample = {w:[workers[w].estimate(data)] for w in range(nWorkers)}\n",
    "        samples[n] = sample\n",
    "        lables.append(data.label)\n",
    "\n",
    "    return (samples, lables, confusion_matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d7d247",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e9c7f7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples, labels, confusion_matrices = generate_sample_data(nSamples, nWorkers, nClasses, .8)\n",
    "samples, labels, confusion_matrices = generate_temporal_dependent_data(nSamples, nWorkers, nClasses, 10, .8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf531a5b",
   "metadata": {},
   "source": [
    "Run EM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ed4df3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dawid_skene import run as run_em\n",
    "\n",
    "_, _, _, _, class_marginals, error_rates, patient_classes = run_em(samples, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d077b94",
   "metadata": {},
   "source": [
    "Run HMM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7334b1e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalHMM(n_components=4, n_features=4, n_iter=100,\n",
       "               random_state=RandomState(MT19937) at 0x186C7882940)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hmmlearn import hmm\n",
    "# Number of possible observations. That can be the same as number of states (for single labeler, or equal to nClasses*nWorkers for multi labelers)\n",
    "labelers_list = [0] # list of labelers\n",
    "n_observations = nClasses\n",
    "# Number of hidden states\n",
    "n_states = nClasses\n",
    "estimated_labels = np.argmax(patient_classes, axis=1)\n",
    "observations = np.array(labels)\n",
    "\n",
    "# Create a Categorical Hidden Markov Model\n",
    "model = hmm.CategoricalHMM(n_components=n_states, n_iter=100)\n",
    "\n",
    "# Fit the model to the observations using the Baum-Welch algorithm\n",
    "model.fit(observations.reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d260a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.00000000e-01 4.00000000e-01 8.08058396e-11 2.87858616e-19]\n",
      " [8.02651808e-18 2.62935017e-17 9.99999996e-01 3.76521034e-09]\n",
      " [2.91917130e-17 3.43910384e-36 1.67753398e-19 1.00000000e+00]\n",
      " [4.69324432e-15 2.11980408e-18 9.99999991e-01 8.66235288e-09]]\n"
     ]
    }
   ],
   "source": [
    "print(model.emissionprob_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a7598b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.91071429e-01 1.67314735e-03 4.46428568e-03 2.79113839e-03]\n",
      " [5.73501664e-29 2.34499952e-01 1.86083785e-02 7.46891669e-01]\n",
      " [1.11111111e-02 3.94326946e-27 9.88888889e-01 2.95304931e-30]\n",
      " [8.05915172e-31 9.72923194e-01 2.69055609e-02 1.71244779e-04]]\n"
     ]
    }
   ],
   "source": [
    "print(model.transmat_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69e4a483",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=model.predict(estimated_labels.reshape(-1,1))\n",
    "accuracy_hmm = int(100 * accuracy_score(observations.reshape(-1,1), z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00239362",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58699cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frobenius_norm(matrix1, matrix2):\n",
    "    # Convert the input matrices to numpy arrays if they are not already\n",
    "    matrix1 = np.array(matrix1)\n",
    "    matrix2 = np.array(matrix2)\n",
    "    \n",
    "    # Calculate the Frobenius norm of the difference\n",
    "    difference = matrix1 - matrix2\n",
    "    norm = np.linalg.norm(difference, 'fro')\n",
    "    \n",
    "    return norm\n",
    "\n",
    "def one_hot_encode(x, n_classes):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "     \"\"\"\n",
    "    return np.eye(n_classes)[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4ca4ad",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "Run this cell only if true labels are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b92ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "true_labels = labels\n",
    "estimated_labels = np.argmax(patient_classes, axis=1)\n",
    "\n",
    "accuracy = int(100 * accuracy_score(true_labels, estimated_labels))\n",
    "\n",
    "print(\"Accuracy: %{}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8de8083",
   "metadata": {},
   "source": [
    "### Average Parameter Estimation Error\n",
    "Run this cell only if true confusion matrices are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d434f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_error_rate = np.mean([frobenius_norm(cm_true, cm_estimate) for cm_true, cm_estimate in zip(confusion_matrices, error_rates)])\n",
    "\n",
    "print(\"Average Parameter Estimation Error: {:.2f}\".format(parameter_error_rate))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyMove_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
